{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5994d45c-2e68-4ef3-abc2-640d55478ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cb88e-67f3-4326-9452-2db1d6ce7d36",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a11b8d0-4b3f-4d67-a56b-20711c81af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c7e3f9-51ea-4cc1-82cc-28dcac8d3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset\n",
    "DATASET_PATH = r'C:\\Users\\Dell\\GAN_Chest_Xray_Synthesis\\data\\chest_xray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd4309cd-de1f-4f59-a5a3-4ca9b37b2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size and batch size\n",
    "IMG_SIZE = 128  # Resize images to 128x128 pixels\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9670429a-1ae5-4ecb-8ac3-d176dc4fa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for training, validation, and testing datasets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values between 0 and 1\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09fe993b-5008-419c-874f-32feb87fae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'train'),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a432fd3f-88ed-4b22-885f-880e45cc2252",
   "metadata": {},
   "source": [
    "## 2. Visualize a Few Sample Images\n",
    "### Visualize some of the training images to ensure everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8eba8b-58e7-4286-a04c-884b47f291d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display a few sample images from the training data\n",
    "sample_images, sample_labels = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e83ae1a-bdde-4474-9ce5-0ca7a09eff29",
   "metadata": {},
   "source": [
    "## 3. Build the GAN Model\n",
    "### 3.1 Generator Model:\n",
    "The generator will create synthetic images from random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef4f08-2bb2-4156-8787-ff4394d46944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128 * 16 * 16, activation=\"relu\", input_dim=100))\n",
    "    model.add(layers.Reshape((16, 16, 128)))\n",
    "    model.add(layers.UpSampling2D())  # Output size: 32x32\n",
    "    model.add(layers.Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    \n",
    "    model.add(layers.UpSampling2D())  # Output size: 64x64\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    \n",
    "    model.add(layers.UpSampling2D())  # Output size: 128x128\n",
    "    model.add(layers.Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.Activation(\"tanh\"))  # Output in the range [-1, 1]\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a351bf-d31f-4418-a5e6-593d94ae7577",
   "metadata": {},
   "source": [
    "### 3.2 Discriminator Model:\n",
    "The discriminator will classify real and synthetic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16d4f7-49f7-4817-b675-cb14f11b6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, input_shape=(128, 128, 1), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Output 1 for real, 0 for fake\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779315f1-784f-479d-9670-8f1e8bdba2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'train'),\n",
    "    target_size=(128, 128),  # Make sure the images are resized to 128x128\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'  # Since the input expects single-channel (grayscale) images\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'val'),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'test'),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2e6c9-8e6c-40f7-b5f1-373e2b0d66cd",
   "metadata": {},
   "source": [
    "## 4. Compile the Models\n",
    "### Compile both the generator and discriminator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb719ba-ed4d-4e1e-857e-b42c06e60f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile discriminator\n",
    "discriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# GAN combines the generator and discriminator\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # Freeze the discriminator during generator training\n",
    "    model = tf.keras.Sequential([generator, discriminator])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58513a4d-f4d0-43fa-b2eb-236324854767",
   "metadata": {},
   "source": [
    "## 5. Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f12e0-645c-4c48-a1d6-ea7ae9ae12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_gan(gan, generator, discriminator, dataset, epochs, batch_size):\n",
    "    real_label = np.ones((batch_size, 1))\n",
    "    fake_label = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(batch_size):\n",
    "            # Train the discriminator with real images\n",
    "            real_images, _ = next(dataset)\n",
    "            d_loss_real = discriminator.train_on_batch(real_images, real_label)\n",
    "\n",
    "            # Train the discriminator with fake images\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            fake_images = generator.predict(noise)\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_images, fake_label)\n",
    "\n",
    "            # Train the generator via the GAN model\n",
    "            g_loss = gan.train_on_batch(noise, real_label)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, G Loss: {g_loss}\")\n",
    "\n",
    "# Set training parameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Start training\n",
    "train_gan(gan, generator, discriminator, train_generator, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a8253-a305-48c2-a0d4-f8361ac13050",
   "metadata": {},
   "source": [
    "## 6.Generate and Visualize Images\n",
    "### Generate synthetic images from the generator and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82825e-8b2d-45b8-9ad1-b411d4b2872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic images\n",
    "noise = np.random.normal(0, 1, (10, 100))  # Generate random noise\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# Visualize the generated images\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(10):\n",
    "    plt.imshow(generated_images[i].reshape(128, 128), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc3fad-8cdf-47c1-b254-bb1950a7514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "def save_generated_images(epoch, generator, num_examples=10):\n",
    "    noise = np.random.normal(0, 1, (num_examples, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    # Rescale images from [-1, 1] to [0, 1]\n",
    "    generated_images = (generated_images + 1) / 2.0\n",
    "\n",
    "    plt.figure(figsize=(10, 1))\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(1, num_examples, i+1)\n",
    "        plt.imshow(generated_images[i].reshape(128, 128), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save generated images to results folder\n",
    "    plt.savefig(f\"results/generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed15ac-8e75-451f-89a5-34b5862ab5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "def save_model_weights(generator, discriminator, epoch):\n",
    "    generator.save(f\"models/generator_epoch_{epoch}.h5\")\n",
    "    discriminator.save(f\"models/discriminator_epoch_{epoch}.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN Project",
   "language": "python",
   "name": "gan_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
